{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_CBOW.ipynb","provenance":[{"file_id":"https://github.com/nickvdw/word2vec-from-scratch/blob/master/word2vec.ipynb","timestamp":1624821685275}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"x5VOelR7BYQ1"},"source":["%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCnATRPgBZEd"},"source":["import numpy as np\n","import keras.backend as K\n","import tensorflow as tf\n","import operator\n","from tensorflow import keras\n","from keras.utils import np_utils\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Reshape, Lambda\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.preprocessing import sequence\n","from sklearn.metrics.pairwise import cosine_distances\n","\n","from sklearn.manifold import TSNE\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.neighbors import NearestNeighbors as nn\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCd0zUO1AKjY"},"source":["### Import file"]},{"cell_type":"code","metadata":{"id":"Gz8Z5gCDBhSl"},"source":["file_name = 'corpus.txt'\n","corpus = open(file_name).readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3jUMh4K7pAf","executionInfo":{"status":"ok","timestamp":1624955657792,"user_tz":-330,"elapsed":17,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"495a3356-7c3b-4b01-81af-2658815293e2"},"source":["corpus"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I am Manikesh of IIT Kanpur\\n',\n"," 'Myself Keshav of IIT Kanpur \\n',\n"," 'You are Keshav of IIT Kanpur \\n',\n"," 'He is Manikesh of IIT Kanpur\\n',\n"," 'Kanpur is in UP \\n',\n"," 'Lucknow is close to Kanpur\\n',\n"," 'Lucknow is capital of UP\\n']"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"zkbk32wHANnD"},"source":["### Data preprocessing\n"]},{"cell_type":"code","metadata":{"id":"37PyOHq2BkY4"},"source":["# Remove sentences with fewer than 3 words\n","corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n","\n","# Remove punctuation in text and fit tokenizer on entire corpus\n","tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n","tokenizer.fit_on_texts(corpus)\n","\n","# Convert text to sequence of integer values\n","corpus = tokenizer.texts_to_sequences(corpus)\n","n_samples = sum(len(s) for s in corpus) # Total number of words in the corpus\n","V = len(tokenizer.word_index) + 1 # Total number of unique words in the corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILdA_IimBlte","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955658568,"user_tz":-330,"elapsed":787,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"6576d291-8bca-4b82-f82a-923f41c31e02"},"source":["n_samples, V"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(37, 19)"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_sw_ziN7h2z","executionInfo":{"status":"ok","timestamp":1624955658568,"user_tz":-330,"elapsed":34,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"e4664dbe-1444-411d-d6b6-fd0a998dffd2"},"source":["corpus"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[9, 10, 5, 2, 3, 1],\n"," [11, 6, 2, 3, 1],\n"," [12, 13, 6, 2, 3, 1],\n"," [14, 4, 5, 2, 3, 1],\n"," [1, 4, 15, 7],\n"," [8, 4, 16, 17, 1],\n"," [8, 4, 18, 2, 7]]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"fRbpue0WBms6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955658569,"user_tz":-330,"elapsed":28,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"60f130b2-279e-47f1-ad2b-51d17afe0b20"},"source":["# Example of how word to integer mapping looks like in the tokenizer\n","print(list((tokenizer.word_index.items())))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('kanpur', 1), ('of', 2), ('iit', 3), ('is', 4), ('manikesh', 5), ('keshav', 6), ('up', 7), ('lucknow', 8), ('i', 9), ('am', 10), ('myself', 11), ('you', 12), ('are', 13), ('he', 14), ('in', 15), ('close', 16), ('to', 17), ('capital', 18)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Er86VxH9BqI9"},"source":["# Parameters\n","window_size = 2 \n","window_size_corpus = 4\n","\n","# Set numpy seed for reproducible results\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4z9Lt6pAZEw"},"source":["## CBOW\n"]},{"cell_type":"code","metadata":{"id":"KMhI_sWFTXDW"},"source":["from keras.preprocessing import sequence\n","\n","# Prepare the data for the CBOW model\n","def generate_data_cbow(corpus, window_size, V):\n","    all_in = []\n","    all_out = []\n","\n","    # Iterate over all sentences\n","    for sentence in corpus:\n","        L = len(sentence)\n","        for index, word in enumerate(sentence):\n","            start = index - window_size\n","            end = index + window_size + 1\n","\n","            # Empty list which will store the context words\n","            context_words = []\n","            for i in range(start, end):\n","                # Skip the 'same' word\n","                if i != index:\n","                    # Add a word as a context word if it is within the window size\n","                    if 0 <= i < L:\n","                        context_words.append(sentence[i])\n","                    else:\n","                        # Pad with zero if there are no words \n","                        context_words.append(0)\n","            # Append the list with context words\n","            all_in.append(context_words)\n","\n","            # Add one-hot encoding of the target word\n","            all_out.append(to_categorical(word, V))\n","                 \n","    return (np.array(all_in), np.array(all_out))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aRKDTZ_iCrIe"},"source":["For the CBOW model, we generate the training data differently compared to how we did it for the Skipgram model. With the CBOW model, we want to predict words based on their context. We do this by using a window around the word we want to predict. In our code, this window is represented by the `window_size`. All words contained in the window are the context words. Note that if we want to predict the first or final few words of a sentence (depends on the window size), it might be the case that our window reaches the previous or next sentence, respectively. In such a case, the window around the target word is restricted to the words that are in the same sentence. In the code, we solve this by using padding, which ensures that all sequences of context words the same length. For the padding, we simply use a value of 0."]},{"cell_type":"code","metadata":{"id":"QC-Rvi9uVO5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955658570,"user_tz":-330,"elapsed":24,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"401cd26a-a883-4ed5-a647-0c266fd28df4"},"source":["# Create the training data\n","X_cbow, y_cbow = generate_data_cbow(corpus, window_size, V)\n","print(list((tokenizer.word_index.items())))\n","print('X_cbow = ',X_cbow,'\\ny_cbow = ',y_cbow)\n","print('V = ',V)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('kanpur', 1), ('of', 2), ('iit', 3), ('is', 4), ('manikesh', 5), ('keshav', 6), ('up', 7), ('lucknow', 8), ('i', 9), ('am', 10), ('myself', 11), ('you', 12), ('are', 13), ('he', 14), ('in', 15), ('close', 16), ('to', 17), ('capital', 18)]\n","X_cbow =  [[ 0  0 10  5]\n"," [ 0  9  5  2]\n"," [ 9 10  2  3]\n"," [10  5  3  1]\n"," [ 5  2  1  0]\n"," [ 2  3  0  0]\n"," [ 0  0  6  2]\n"," [ 0 11  2  3]\n"," [11  6  3  1]\n"," [ 6  2  1  0]\n"," [ 2  3  0  0]\n"," [ 0  0 13  6]\n"," [ 0 12  6  2]\n"," [12 13  2  3]\n"," [13  6  3  1]\n"," [ 6  2  1  0]\n"," [ 2  3  0  0]\n"," [ 0  0  4  5]\n"," [ 0 14  5  2]\n"," [14  4  2  3]\n"," [ 4  5  3  1]\n"," [ 5  2  1  0]\n"," [ 2  3  0  0]\n"," [ 0  0  4 15]\n"," [ 0  1 15  7]\n"," [ 1  4  7  0]\n"," [ 4 15  0  0]\n"," [ 0  0  4 16]\n"," [ 0  8 16 17]\n"," [ 8  4 17  1]\n"," [ 4 16  1  0]\n"," [16 17  0  0]\n"," [ 0  0  4 18]\n"," [ 0  8 18  2]\n"," [ 8  4  2  7]\n"," [ 4 18  7  0]\n"," [18  2  0  0]] \n","y_cbow =  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","V =  19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qAu_XWiVVSZw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955658571,"user_tz":-330,"elapsed":20,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"896f33c0-591a-4083-9772-a8f8260dbf02"},"source":["# Create the CBOW architecture\n","dim = 2\n","\n","#for dim in dims:\n","cbow = Sequential()\n","\n","    # Add an Embedding layer\n","cbow.add(Embedding(input_dim=V, \n","                   output_dim=dim,\n","                   input_length=window_size*2, # Note that we now have 2L words for each input entry\n","                   embeddings_initializer='glorot_uniform'))\n","\n","cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim, )))\n","\n","cbow.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n","\n","cbow.compile(optimizer=keras.optimizers.Adam(),\n","             loss='categorical_crossentropy',\n","             metrics=['accuracy'])\n","    \n","cbow.summary()\n","print(\"\")\n","#cbow_models.append(cbow)\n","#cbow.get_weights()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 4, 2)              38        \n","_________________________________________________________________\n","lambda_2 (Lambda)            (None, 2)                 0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 19)                57        \n","=================================================================\n","Total params: 95\n","Trainable params: 95\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3rlM4jspVVmq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955659465,"user_tz":-330,"elapsed":904,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"fb234e7b-1018-4a54-d44b-e898d36214f5"},"source":["# Train CBOW model\n","cbow.fit(X_cbow, y_cbow, batch_size=64, epochs=50, verbose=1)\n","print(\"\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1/1 [==============================] - 0s 403ms/step - loss: 2.9341 - accuracy: 0.0541\n","Epoch 2/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9332 - accuracy: 0.0541\n","Epoch 3/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9323 - accuracy: 0.0541\n","Epoch 4/50\n","1/1 [==============================] - 0s 4ms/step - loss: 2.9313 - accuracy: 0.0541\n","Epoch 5/50\n","1/1 [==============================] - 0s 4ms/step - loss: 2.9304 - accuracy: 0.0541\n","Epoch 6/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9294 - accuracy: 0.0541\n","Epoch 7/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9285 - accuracy: 0.0541\n","Epoch 8/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9275 - accuracy: 0.0541\n","Epoch 9/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9266 - accuracy: 0.0541\n","Epoch 10/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9256 - accuracy: 0.0270\n","Epoch 11/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9247 - accuracy: 0.0270\n","Epoch 12/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9238 - accuracy: 0.0270\n","Epoch 13/50\n","1/1 [==============================] - 0s 15ms/step - loss: 2.9228 - accuracy: 0.0270\n","Epoch 14/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9219 - accuracy: 0.0270\n","Epoch 15/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9209 - accuracy: 0.0270\n","Epoch 16/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9200 - accuracy: 0.0270\n","Epoch 17/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9191 - accuracy: 0.0270\n","Epoch 18/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9181 - accuracy: 0.0270\n","Epoch 19/50\n","1/1 [==============================] - 0s 9ms/step - loss: 2.9172 - accuracy: 0.0270\n","Epoch 20/50\n","1/1 [==============================] - 0s 8ms/step - loss: 2.9162 - accuracy: 0.0541\n","Epoch 21/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9153 - accuracy: 0.0270\n","Epoch 22/50\n","1/1 [==============================] - 0s 11ms/step - loss: 2.9144 - accuracy: 0.0270\n","Epoch 23/50\n","1/1 [==============================] - 0s 8ms/step - loss: 2.9134 - accuracy: 0.0270\n","Epoch 24/50\n","1/1 [==============================] - 0s 8ms/step - loss: 2.9125 - accuracy: 0.0270\n","Epoch 25/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9116 - accuracy: 0.0270\n","Epoch 26/50\n","1/1 [==============================] - 0s 8ms/step - loss: 2.9106 - accuracy: 0.0270\n","Epoch 27/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9097 - accuracy: 0.0270\n","Epoch 28/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9088 - accuracy: 0.0270\n","Epoch 29/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9078 - accuracy: 0.0270\n","Epoch 30/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9069 - accuracy: 0.0270\n","Epoch 31/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.9059 - accuracy: 0.0541\n","Epoch 32/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9050 - accuracy: 0.0541\n","Epoch 33/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9041 - accuracy: 0.0541\n","Epoch 34/50\n","1/1 [==============================] - 0s 10ms/step - loss: 2.9031 - accuracy: 0.0541\n","Epoch 35/50\n","1/1 [==============================] - 0s 20ms/step - loss: 2.9022 - accuracy: 0.0541\n","Epoch 36/50\n","1/1 [==============================] - 0s 11ms/step - loss: 2.9013 - accuracy: 0.0541\n","Epoch 37/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9003 - accuracy: 0.0541\n","Epoch 38/50\n","1/1 [==============================] - 0s 10ms/step - loss: 2.8994 - accuracy: 0.0541\n","Epoch 39/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.8985 - accuracy: 0.0541\n","Epoch 40/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.8975 - accuracy: 0.0541\n","Epoch 41/50\n","1/1 [==============================] - 0s 8ms/step - loss: 2.8966 - accuracy: 0.0541\n","Epoch 42/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.8957 - accuracy: 0.0541\n","Epoch 43/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.0541\n","Epoch 44/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.0541\n","Epoch 45/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.8929 - accuracy: 0.0541\n","Epoch 46/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.8919 - accuracy: 0.0541\n","Epoch 47/50\n","1/1 [==============================] - 0s 7ms/step - loss: 2.8910 - accuracy: 0.0541\n","Epoch 48/50\n","1/1 [==============================] - 0s 9ms/step - loss: 2.8901 - accuracy: 0.0541\n","Epoch 49/50\n","1/1 [==============================] - 0s 6ms/step - loss: 2.8891 - accuracy: 0.0541\n","Epoch 50/50\n","1/1 [==============================] - 0s 5ms/step - loss: 2.8882 - accuracy: 0.0541\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cGoH2oaEVXPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624955659466,"user_tz":-330,"elapsed":20,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"7c1b7ecd-ecef-40a1-afc9-b4a7a95b33c9"},"source":["# Save embeddings for vectors of length 50, 150 and 300 using cbow model\n","weights = cbow.get_weights()\n","\n","# Get the embedding matrix\n","embedding = weights[0]\n","\n","weights\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[-0.48724774, -0.17558613],\n","        [ 0.07577548,  0.14390793],\n","        [ 0.41947666, -0.26530123],\n","        [ 0.18717937, -0.14878336],\n","        [-0.23267516,  0.04003462],\n","        [-0.01865107, -0.3936736 ],\n","        [-0.02557449,  0.16233507],\n","        [ 0.13373378, -0.20747308],\n","        [-0.5653055 ,  0.11783456],\n","        [-0.11218169,  0.38029826],\n","        [-0.40187386, -0.48436177],\n","        [-0.27289096,  0.02789403],\n","        [-0.41120037,  0.5335281 ],\n","        [ 0.54245996, -0.2878798 ],\n","        [ 0.17485091, -0.12286229],\n","        [ 0.34241366, -0.20301804],\n","        [-0.12406819,  0.26509294],\n","        [-0.26890078,  0.11849216],\n","        [ 0.1777732 ,  0.47229117]], dtype=float32),\n"," array([[ 0.18372212,  0.03912233,  0.244791  , -0.30860007, -0.565911  ,\n","          0.5557085 ,  0.3071963 , -0.23151024, -0.5258235 , -0.11906597,\n","         -0.12471074, -0.465807  ,  0.3156095 , -0.12478632,  0.43049768,\n","          0.23465972, -0.08589555, -0.13152845, -0.03636632],\n","        [ 0.00148165, -0.3274887 , -0.26604387,  0.3805539 , -0.17662276,\n","          0.15976962,  0.41112503,  0.27599627,  0.31941918, -0.41476262,\n","          0.00850939, -0.301199  , -0.31126112, -0.23708962, -0.37008408,\n","          0.23001778,  0.32108888,  0.5399106 ,  0.16465726]],\n","       dtype=float32),\n"," array([-0.04969934,  0.04978332,  0.04976697,  0.049613  ,  0.04943078,\n","         0.0456213 ,  0.04530032,  0.02611446, -0.00941152, -0.04970518,\n","        -0.04946905, -0.04963079, -0.04937305, -0.04950758, -0.04951597,\n","        -0.04930414, -0.049494  , -0.04947685, -0.04941207], dtype=float32)]"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioJXPYiH6VhQ","executionInfo":{"status":"ok","timestamp":1624955777099,"user_tz":-330,"elapsed":354,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"8bbd27ec-b434-49c2-d566-3ecaf1091052"},"source":["len(corpus)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-x_Yzma7A4f","executionInfo":{"status":"ok","timestamp":1624956186269,"user_tz":-330,"elapsed":387,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"508ea322-ef16-4f04-b478-51ca6e3996a1"},"source":["print(list((tokenizer.word_index.items()))[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["kanpur\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iJk3SVoZ5MKd"},"source":["k = embedding[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCMGkEnJ6mTD"},"source":["l = embedding[8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Arv8EB_d6_kW","executionInfo":{"status":"ok","timestamp":1624956073055,"user_tz":-330,"elapsed":406,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"de3873f5-c798-4fc9-b7a1-ee469ecf27b2"},"source":["embedding[0][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.48724774"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2DMwNTt9MAN","executionInfo":{"status":"ok","timestamp":1624956526786,"user_tz":-330,"elapsed":397,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"bee528d6-740d-4a85-f962-6fe90983401f"},"source":["len(embedding)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yyJZjWFr9OgC","executionInfo":{"status":"ok","timestamp":1624956543376,"user_tz":-330,"elapsed":371,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"01303d75-2499-417e-ad50-097200376662"},"source":["len(list((tokenizer.word_index.items())))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrnkMVlF9Wt1","executionInfo":{"status":"ok","timestamp":1624956751173,"user_tz":-330,"elapsed":361,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"b131f628-8088-460f-d5c3-71f678d9e0b8"},"source":["words = list((tokenizer.word_index.items()))\n","words.insert(0,('unkown',0))\n","words"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('unkown', 0),\n"," ('kanpur', 1),\n"," ('of', 2),\n"," ('iit', 3),\n"," ('is', 4),\n"," ('manikesh', 5),\n"," ('keshav', 6),\n"," ('up', 7),\n"," ('lucknow', 8),\n"," ('i', 9),\n"," ('am', 10),\n"," ('myself', 11),\n"," ('you', 12),\n"," ('are', 13),\n"," ('he', 14),\n"," ('in', 15),\n"," ('close', 16),\n"," ('to', 17),\n"," ('capital', 18)]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vVqO8cD9cGM","executionInfo":{"status":"ok","timestamp":1624956588937,"user_tz":-330,"elapsed":391,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"19bf200a-7c39-4605-bc4e-d59cffb7d06a"},"source":["embedding"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.48724774, -0.17558613],\n","       [ 0.07577548,  0.14390793],\n","       [ 0.41947666, -0.26530123],\n","       [ 0.18717937, -0.14878336],\n","       [-0.23267516,  0.04003462],\n","       [-0.01865107, -0.3936736 ],\n","       [-0.02557449,  0.16233507],\n","       [ 0.13373378, -0.20747308],\n","       [-0.5653055 ,  0.11783456],\n","       [-0.11218169,  0.38029826],\n","       [-0.40187386, -0.48436177],\n","       [-0.27289096,  0.02789403],\n","       [-0.41120037,  0.5335281 ],\n","       [ 0.54245996, -0.2878798 ],\n","       [ 0.17485091, -0.12286229],\n","       [ 0.34241366, -0.20301804],\n","       [-0.12406819,  0.26509294],\n","       [-0.26890078,  0.11849216],\n","       [ 0.1777732 ,  0.47229117]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"qn2nQVYe7Hry","executionInfo":{"status":"ok","timestamp":1624956849099,"user_tz":-330,"elapsed":761,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"a6286b88-59b5-4721-c2dc-4bd02b02ccc9"},"source":["fig , ax = plt.subplots(1,1,figsize = (10,10))\n","for i in range(len(embedding)):\n","  plt.scatter(embedding[i][0],embedding[i][1])\n","  ax.annotate(words[i][0],(embedding[i][0] + 0.01,embedding[i][1] + 0.01))\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFToCZU-xCWs","executionInfo":{"status":"ok","timestamp":1624956905491,"user_tz":-330,"elapsed":367,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"522b9bca-5dbe-44da-a7c9-e748fd958ab6"},"source":["np.linalg.norm(k-l)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.641611"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"HnpspRr3wpv3"},"source":["# Get word embeddings for each word in the vocabulary, write to file\n","f = open(f'vectors_cbow_2{len(embedding[0])}.txt', 'w')\n","\n","# Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n","columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n","\n","# Start writing to the file, start with the column names\n","f.write(\" \".join(columns))\n","f.write(\"\\n\")\n","\n","for word, i in tokenizer.word_index.items():\n","  f.write(word)\n","  f.write(\" \")\n","  f.write(\" \".join(map(str, list(embedding[i,:]))))\n","  f.write(\"\\n\")\n","  f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M0sU1JORATvX"},"source":["## Skipgram"]},{"cell_type":"code","metadata":{"id":"Udp1xKcDBu0v"},"source":["# Prepare data for the skipgram model\n","def generate_data_skipgram(corpus, window_size, V):\n","    maxlen = window_size * 2\n","    all_in = []\n","    all_out = []\n","    for words in corpus:\n","        L = len(words)\n","        for index, word in enumerate(words):\n","            p = index - window_size\n","            n = index + window_size + 1\n","\n","            in_words = []\n","            labels = []\n","            for i in range(p, n):\n","                if i != index and 0 <= i < L:\n","                    # Add the input word\n","                    all_in.append(word)\n","                    # Add one-hot of the context words\n","                    all_out.append(to_categorical(words[i], V))\n","\n","    return (np.array(all_in), np.array(all_out))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JA9BcRTZ8FM6"},"source":["We break down each (target word, context word**s**) pair into (target word, context word) pairs. This is done with the `generate_data_skipgram` method above. This method returns two NumPy arrays: `x` (input, i.e., target word) and `y` (output, i.e., context word). We can now use this method to generate our training data.\n"]},{"cell_type":"code","metadata":{"id":"qXBGNrKTB0tO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624863208579,"user_tz":-330,"elapsed":410,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"931ba971-2a9e-4475-c11e-8a5c7c2227ca"},"source":["# Create training data\n","X_skip, y_skip = generate_data_skipgram(corpus, window_size, V)\n","X_skip, y_skip"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([4, 4, 5, 5, 5, 6, 6, 6, 6, 1, 1, 1, 1, 2, 2, 2, 3, 3, 7, 7, 8, 8,\n","        8, 1, 1, 1, 1, 2, 2, 2, 3, 3]),\n"," array([[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"J1FTkStoDLFQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624863332799,"user_tz":-330,"elapsed":417,"user":{"displayName":"makam manikesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguqxFbquDYehqHoRcyaWuLyL3gxfLewcdgeLDjvg4=s64","userId":"16814793375038162342"}},"outputId":"03948875-5d12-4ea7-851b-da691f956683"},"source":["# Create skipgram architecture\n","skipgram_models = []\n","\n","    # Initialize a Keras Sequential model\n","skipgram = Sequential()\n","\n","    # Add an Embedding layer\n","skipgram.add(Embedding(input_dim=V,\n","                       output_dim=dim,\n","                       input_length=1,\n","                       embeddings_initializer='glorot_uniform'))\n","\n","    # Add a Reshape layer, which reshapes the output of the embedding layer (1,dim) to (dim,)\n","skipgram.add(Reshape((dim, )))\n","\n","    # Add a final Dense layer with the same size as in [1]\n","skipgram.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n","\n","    # Compile the model with a suitable loss function and select an optimizer.\n","    # Optimizer Adagrad was used in paper\n","skipgram.compile(optimizer=keras.optimizers.Adam(),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","    \n","skipgram.summary()\n","print(\"\")\n","skipgram_models.append(skipgram)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 1, 2)              18        \n","_________________________________________________________________\n","reshape (Reshape)            (None, 2)                 0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 9)                 27        \n","=================================================================\n","Total params: 45\n","Trainable params: 45\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0hxaiIYg99q6"},"source":["We create a list that stores all dimensions (50, 150, and 300). We iterate over this list and create models for each dimension. Note that the base model we created is equal to the model used in Practical 3.1. \n","\n","Since we want to predict a context word using a single input word, our `input_length` equals 1. The input dimension simply equals the size of our vocabulary, namely `V`. This is because we use a one-hot encoding. In this one-hot encoding, the index that represents the input word equals 1, and all other indices equal 0. Since we have to consider all words in our vocabulary, the one-hot encoding is of dimension `V`. We do not need to perform the one-hot encoding ourselves for the input data since this is done by the embedding layer in our model.\n","\n","Since we want to predict a certain context word, which can have `V` possible outcomes, we use a Softmax layer with `V` units such that we can map a probability to each word in `V`. Since our problem is a typical multiclass classification problem, we use **categorical** cross-entropy as our loss function.\n","\n","We use `adam` as our optimizer, which is an adaptive learning rate optimization algorithm that has been designed specifically for training deep neural networks [2]. We have tried various optimizers, such as SGD, RMSProp, Adam, and Adagrad. Adam seemed to perform the best with respect to the loss and accuracy. We also tried varying the learning rate. We initialize the weights with values from a `glorot_uniform` distribution since we were also requested to use this initializer in Practical 3.1, which tackled a very similar problem compared to the one we are trying to solve in this assignment.\n","\n","[2] https://arxiv.org/pdf/1412.6980.pdf"]},{"cell_type":"code","metadata":{"id":"a9eg0xPoDP9B"},"source":["# Training the skipgram models\n","for skipgram in skipgram_models:\n","    skipgram.fit(X_skip, y_skip, batch_size=64, epochs=13, verbose=1)\n","    print(\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jr_d7eqkBkfA"},"source":["We fit each model that considers a varying number of dimensions with a batch size of 64 and 13 epochs. \n","\n","We observe that the loss decreases very slowly. Moreover, we observe a slowly increasing accuracy. We use accuracy as a metric, so that we can get sort of an idea of when to stop. The bad thing about our approach is that we train all models for an equal number of epochs this way when that is not necessarily the best course of action, but let us not focus too much on this now as the training does not take that long anyway and we just want to create word embeddings. We used an equal number of epochs for all models to make it easier to compare the losses and accuracies of the different models at equal numbers of epochs. After 12 epochs for the model that considers 50 dimensions, we observe that the accuracy does not increase significantly anymore (even decreases a bit during one epoch). This can also be observed for the model with 150 dimensions after epoch 6. For the model with 300 dimensions, we can already stop after 4 epochs since the accuracy only keeps decreasing. Hence, we observe that training these models for more epochs does not necessarily lead to a better accuracy.\n","\n","A major reason for this low accuracy is the corpus size being of relatively small size. Our corpus, namely `alice.txt`, has only 26,283 words before processing the file, which is a lot less than the millions of words that are mentioned by Mikolov et al. in [1]. We suspect that this results in our models simply not being able to learn much from our corpus. This is highlighted even more by Mikolov et al. [1] in  tables 2 and 3 in [1]. Since we trained our models on a relatively small corpus, low accuracies were to be expected. Rezaeinia et al. [3] further support this statement. \n","\n","[3] https://arxiv.org/ftp/arxiv/papers/1711/1711.08609.pdf"]},{"cell_type":"code","metadata":{"id":"eGEHlkQ4DShO"},"source":["for skipgram in skipgram_models:\n","    # Save embeddings for vectors of length 50, 150 and 300 using skipgram model\n","    weights = skipgram.get_weights()\n","\n","    # Get the embedding matrix\n","    embedding = weights[0]\n","\n","    # Get word embeddings for each word in the vocabulary, write to file\n","    f = open(f\"vectors_skipgram_{len(embedding[0])}.txt\", \"w\")\n","\n","    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n","    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n","\n","    # Start writing to the file, start with the column names\n","    f.write(\" \".join(columns))\n","\n","    # Start a new line\n","    f.write(\"\\n\")\n","\n","    for word, i in tokenizer.word_index.items():\n","        f.write(word)\n","        f.write(\" \")\n","        f.write(\" \".join(map(str, list(embedding[i,:]))))\n","        f.write(\"\\n\")\n","    f.close()"],"execution_count":null,"outputs":[]}]}